{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before you start:\n",
    "- Read the SQLtoPythonViz.md file and use the resources\n",
    "- Happy learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy, pandas and pymysql sqlalchemy (following what you have learned in previous lessons):\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1 - Load and Evaluate the Datasets\n",
    "\n",
    "#### In this challenge we will load data from MySQL Sakila database or Sian's Harry Potter MySQL database, by querying and evaluating the results returned using MySQL we can be selective about the data used to make visualisation with seaborn/matplotlib very easy\n",
    "\n",
    "In the cell below, create a mysql engine for your local mysql instance and include your username, password and database schema name by creating a variable connection string following the following pattern:\n",
    "\n",
    "create_engine(‘dialect+driver://username:password@host:port/database’)\n",
    "\n",
    "This is the format to create the engine for a local mysql connection\n",
    "\n",
    "\n",
    "connection_string = 'mysql+pymysql://root:' + password + '@localhost/db'\n",
    "\n",
    "\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this connection to load data with a sql query which connects the target tables in your database using joins, selects the fields you wish to work with and any aggregation columns + grouping / window function new columns or filters by where/having as appropriate. You can draw on any of the labs or lessons to establish what your query should look like. Its ok if this stage is a little trial and error!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's start examining the dataset to ensure we have the data we want to visualise.\n",
    "\n",
    "First look at the first five rows using the `head` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets use the `info` function to see the dtypes and row counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll examine the `describe` function to see the descriptive statistics for the numeric variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### At this stage it may be necessary to load another set of data with an additional mysql query and repeat the stages above - perhaps you are thinking to join the results of your two queries together or you think that both should be visualised separately to answer the question you came up with?\n",
    "\n",
    "Do this in the following 3 cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploratory Data Analysis\n",
    "You might benefit from doing some elementary EDA at this stage before jumping into plotting data, as this can help you grasp the shape, diversity and gaps in the data you have selected. This is a timesaver!\n",
    "\n",
    "For this task you can use matplotlib/seaborn so you will need to import them, then work with : \n",
    "\n",
    "- df.hist()\n",
    "- sns.boxplot(x=df[\"colname\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here (import visual libraries)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here (histogram all numericals)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here (box plot to see outliers for specific columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional - if you are using more than one sql query \n",
    "\n",
    "If you decided to load two dataframes from two separate mysql queries and need to merge them using the merge concat or join functions, do so now. You can follow [this tutorial](https://realpython.com/pandas-merge-join-and-concat/) for more information about bringing dataframes together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2 - Export your data frame as a csv \n",
    "\n",
    "Export df to a csv file using the `df.to_csv` function, filtered if suitable, excluding any columns which are not useful for further analysis  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3: Visualise relationships found in the data\n",
    "\n",
    "At this stage you can visualise the data in your chosen tool, Tableau, Excel, Python(matploitlib,seaborn)\n",
    "\n",
    "**Business Question**: think about what are the question(s) you want to answer with the data you have gathered from the MySQL database. Make the question as specific as possible \n",
    "- for example, which eye colour is most common per Hogwarts house? \n",
    "- for example, are childrens films rented more frequently on weekends than comedies?\n",
    "\n",
    "**Visuals**: Think about what plot type best supports answering your question(s). Each plot/ visualisation should have an appropriate title, legend and axis labels, so the meaning is as clear as possible without needing a caption. Make use of colour pallettes ! dont just create a blue plot :) \n",
    "\n",
    "**Bonus** - find a way to amend your visualisation to add in at least one other interesting data point you have identified in the data to enhance the plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (if plotting in python) Your code here: \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
